{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VFu2xDaUSYaU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/dataset'"
      ],
      "metadata": {
        "id": "XteV_3aoSm58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels - age, gender, ethnicity\n",
        "image_paths = []\n",
        "age_labels = []\n",
        "gender_labels = []\n",
        "\n",
        "for filename in tqdm(os.listdir(BASE_DIR)):\n",
        "    image_path = os.path.join(BASE_DIR, filename)\n",
        "    temp = filename.split('_')\n",
        "    age = int(temp[0])\n",
        "    gender = int(temp[1])\n",
        "    image_paths.append(image_path)\n",
        "    age_labels.append(age)\n",
        "    gender_labels.append(gender)"
      ],
      "metadata": {
        "id": "K-PabOW2SsaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to dataframe\n",
        "df = pd.DataFrame()\n",
        "df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tbG3wTg0Swvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map labels for gender\n",
        "gender_dict = {0:'Male', 1:'Female'}"
      ],
      "metadata": {
        "id": "3rSTiiBqS0WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "img = Image.open(df['image'][0])\n",
        "plt.axis('off')\n",
        "plt.imshow(img);"
      ],
      "metadata": {
        "id": "j2fD-DnjS6Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['age'])"
      ],
      "metadata": {
        "id": "WvZfoUmoTMdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['gender'])"
      ],
      "metadata": {
        "id": "w88O0k8ITNTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to display grid of images\n",
        "plt.figure(figsize=(20, 20))\n",
        "files = df.iloc[0:25]\n",
        "\n",
        "for index, file, age, gender in files.itertuples():\n",
        "    plt.subplot(5, 5, index+1)\n",
        "    img = load_img(file)\n",
        "    img = np.array(img)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Age: {age} Gender: {gender_dict[gender]}\")\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "ueEmGP67TQrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images):\n",
        "    features = []\n",
        "    for image in tqdm(images):\n",
        "        img = load_img(image, color_mode='grayscale')\n",
        "        img = img.resize((128, 128), Image.ANTIALIAS)\n",
        "        img = np.array(img)\n",
        "        features.append(img)\n",
        "\n",
        "    features = np.array(features)\n",
        "    # ignore this step if using RGB\n",
        "    features = features.reshape(len(features), 128, 128, 1)\n",
        "    return features"
      ],
      "metadata": {
        "id": "Bd9lpguSTUmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = extract_features(df['image'])"
      ],
      "metadata": {
        "id": "uxlNOjW1TaJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "3wcm1L_aTbhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the images\n",
        "X = X/255.0"
      ],
      "metadata": {
        "id": "6BOFQePfTjDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_gender = np.array(df['gender'])\n",
        "y_age = np.array(df['age'])"
      ],
      "metadata": {
        "id": "EMO504h2TprS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 128, 1)"
      ],
      "metadata": {
        "id": "IGLk-vfrTqg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input((input_shape))\n",
        "# convolutional layers\n",
        "conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)\n",
        "maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)\n",
        "conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)\n",
        "maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)\n",
        "conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)\n",
        "maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)\n",
        "conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)\n",
        "maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)\n",
        "\n",
        "flatten = Flatten() (maxp_4)\n",
        "\n",
        "# fully connected layers\n",
        "dense_1 = Dense(256, activation='relu') (flatten)\n",
        "dense_2 = Dense(256, activation='relu') (flatten)\n",
        "\n",
        "dropout_1 = Dropout(0.4) (dense_1)\n",
        "dropout_2 = Dropout(0.4) (dense_2)\n",
        "\n",
        "output_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)\n",
        "output_2 = Dense(1, activation='relu', name='age_out') (dropout_2)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[output_1, output_2])\n",
        "\n",
        "model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['accuracy', 'mae'])"
      ],
      "metadata": {
        "id": "7LEaVrTlTtgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "metadata": {
        "id": "4fuAkErjT3dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "history = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=30, validation_split=0.2)"
      ],
      "metadata": {
        "id": "etr5G6RDT6l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results for gender\n",
        "acc = history.history['gender_out_accuracy']\n",
        "val_acc = history.history['val_gender_out_accuracy']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YMo5__43T-kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot results for age\n",
        "loss = history.history['age_out_mae']\n",
        "val_loss = history.history['val_age_out_mae']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training MAE')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation MAE')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V5L1FTnZUDff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 100\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
      ],
      "metadata": {
        "id": "sWcqFolIUHOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 3000\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
      ],
      "metadata": {
        "id": "JzdH_Bx0UKQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_index = 9\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(y_age[image_index])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
      ],
      "metadata": {
        "id": "xf2olSrNUNvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiosp5OIUUkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}